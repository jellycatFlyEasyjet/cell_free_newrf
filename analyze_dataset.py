#!/usr/bin/env python3
"""
åˆ†æ conference_500STA_4APs.pkl æ•°æ®é›†ä¸­CFRæ•°æ®çš„åˆ†å¸ƒæƒ…å†µ
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter
import warnings
warnings.filterwarnings('ignore')

def analyze_cfr_dataset(dataset_path):
    """åˆ†æCFRæ•°æ®é›†çš„è¯¦ç»†ä¿¡æ¯"""
    
    print("="*80)
    print("ğŸ“Š CFRæ•°æ®é›†åˆ†ææŠ¥å‘Š")
    print("="*80)
    
    # åŠ è½½æ•°æ®é›†
    try:
        dataset = pd.read_pickle(dataset_path)
        print(f"âœ… æˆåŠŸåŠ è½½æ•°æ®é›†: {dataset_path}")
        print(f"ğŸ“‹ æ•°æ®é›†å½¢çŠ¶: {dataset.shape}")
    except Exception as e:
        print(f"âŒ åŠ è½½æ•°æ®é›†å¤±è´¥: {e}")
        return
    
    print("\n" + "-"*50)
    print("ğŸ” åŸºæœ¬ä¿¡æ¯")
    print("-"*50)
    
    # åŸºæœ¬ä¿¡æ¯
    print(f"æ€»è®°å½•æ•°: {len(dataset)}")
    print(f"åˆ—å: {list(dataset.columns)}")
    print(f"æ•°æ®ç±»å‹:")
    for col in dataset.columns:
        print(f"  {col}: {dataset[col].dtype}")
    
    # æ£€æŸ¥ç¼ºå¤±å€¼
    missing_data = dataset.isnull().sum()
    if missing_data.sum() > 0:
        print(f"\nâš ï¸ ç¼ºå¤±æ•°æ®:")
        print(missing_data[missing_data > 0])
    else:
        print("\nâœ… æ— ç¼ºå¤±æ•°æ®")
    
    print("\n" + "-"*50)
    print("ğŸ“¡ APå’ŒSTAåˆ†å¸ƒ")
    print("-"*50)
    
    # APå’ŒSTAåˆ†å¸ƒ
    if 'TxID' in dataset.columns:
        tx_counts = Counter(dataset['TxID'])
        print(f"AP (TxID) æ•°é‡: {len(tx_counts)}")
        print(f"APåˆ†å¸ƒ: {dict(tx_counts)}")
    
    if 'RxID' in dataset.columns:
        rx_counts = Counter(dataset['RxID'])
        print(f"STA (RxID) æ•°é‡: {len(rx_counts)}")
        print(f"STA IDèŒƒå›´: {min(rx_counts.keys())} - {max(rx_counts.keys())}")
    
    print("\n" + "-"*50)
    print("ğŸ“Š CFRæ•°æ®åˆ†æ")
    print("-"*50)
    
    # CFRæ•°æ®åˆ†æ
    if 'CSI' in dataset.columns:
        print("CSI (Channel State Information) æ•°æ®:")
        
        # éšæœºé‡‡æ ·ä¸€äº›CFRæ•°æ®è¿›è¡Œåˆ†æ
        sample_size = min(100, len(dataset))
        sample_indices = np.random.choice(len(dataset), sample_size, replace=False)
        
        cfr_shapes = []
        cfr_magnitudes = []
        cfr_phases = []
        cfr_real_parts = []
        cfr_imag_parts = []
        
        for idx in sample_indices:
            try:
                cfr_data = dataset.iloc[idx]['CSI']
                if isinstance(cfr_data, np.ndarray) and len(cfr_data) > 0:
                    # ç¡®ä¿æ˜¯å¤æ•°æ•°ç»„
                    if np.iscomplexobj(cfr_data):
                        cfr_complex = cfr_data
                    else:
                        cfr_complex = cfr_data.astype(np.complex128)
                    
                    cfr_shapes.append(cfr_complex.shape)
                    cfr_magnitudes.extend(np.abs(cfr_complex.flatten()))
                    cfr_phases.extend(np.angle(cfr_complex.flatten()))
                    cfr_real_parts.extend(np.real(cfr_complex.flatten()))
                    cfr_imag_parts.extend(np.imag(cfr_complex.flatten()))
                    
            except Exception as e:
                print(f"  âš ï¸ å¤„ç†ç¬¬{idx}æ¡è®°å½•æ—¶å‡ºé”™: {e}")
                continue
        
        if cfr_shapes:
            shape_counter = Counter([str(shape) for shape in cfr_shapes])
            print(f"  CFRæ•°æ®å½¢çŠ¶åˆ†å¸ƒ: {dict(shape_counter)}")
            
            if cfr_magnitudes:
                print(f"  å¹…åº¦ç»Ÿè®¡:")
                print(f"    æœ€å°å€¼: {np.min(cfr_magnitudes):.6f}")
                print(f"    æœ€å¤§å€¼: {np.max(cfr_magnitudes):.6f}")
                print(f"    å¹³å‡å€¼: {np.mean(cfr_magnitudes):.6f}")
                print(f"    æ ‡å‡†å·®: {np.std(cfr_magnitudes):.6f}")
                
                print(f"  ç›¸ä½ç»Ÿè®¡ (å¼§åº¦):")
                print(f"    æœ€å°å€¼: {np.min(cfr_phases):.6f}")
                print(f"    æœ€å¤§å€¼: {np.max(cfr_phases):.6f}")
                print(f"    å¹³å‡å€¼: {np.mean(cfr_phases):.6f}")
                print(f"    æ ‡å‡†å·®: {np.std(cfr_phases):.6f}")
                
                print(f"  å®éƒ¨ç»Ÿè®¡:")
                print(f"    æœ€å°å€¼: {np.min(cfr_real_parts):.6f}")
                print(f"    æœ€å¤§å€¼: {np.max(cfr_real_parts):.6f}")
                print(f"    å¹³å‡å€¼: {np.mean(cfr_real_parts):.6f}")
                print(f"    æ ‡å‡†å·®: {np.std(cfr_real_parts):.6f}")
                
                print(f"  è™šéƒ¨ç»Ÿè®¡:")
                print(f"    æœ€å°å€¼: {np.min(cfr_imag_parts):.6f}")
                print(f"    æœ€å¤§å€¼: {np.max(cfr_imag_parts):.6f}")
                print(f"    å¹³å‡å€¼: {np.mean(cfr_imag_parts):.6f}")
                print(f"    æ ‡å‡†å·®: {np.std(cfr_imag_parts):.6f}")
    
    print("\n" + "-"*50)
    print("ğŸ—ºï¸ ä½ç½®ä¿¡æ¯åˆ†æ")
    print("-"*50)
    
    # ä½ç½®ä¿¡æ¯åˆ†æ
    if 'TxPos' in dataset.columns:
        print("APä½ç½® (TxPos) ä¿¡æ¯:")
        tx_positions = []
        for pos in dataset['TxPos'].dropna():
            if isinstance(pos, (list, np.ndarray)) and len(pos) >= 3:
                tx_positions.append(pos[:3])
        
        if tx_positions:
            tx_positions = np.array(tx_positions)
            print(f"  Xåæ ‡èŒƒå›´: {np.min(tx_positions[:, 0]):.2f} - {np.max(tx_positions[:, 0]):.2f}")
            print(f"  Yåæ ‡èŒƒå›´: {np.min(tx_positions[:, 1]):.2f} - {np.max(tx_positions[:, 1]):.2f}")
            print(f"  Zåæ ‡èŒƒå›´: {np.min(tx_positions[:, 2]):.2f} - {np.max(tx_positions[:, 2]):.2f}")
    
    if 'RxPos' in dataset.columns:
        print("\nSTAä½ç½® (RxPos) ä¿¡æ¯:")
        rx_positions = []
        for pos in dataset['RxPos'].dropna():
            if isinstance(pos, (list, np.ndarray)) and len(pos) >= 3:
                rx_positions.append(pos[:3])
        
        if rx_positions:
            rx_positions = np.array(rx_positions)
            print(f"  Xåæ ‡èŒƒå›´: {np.min(rx_positions[:, 0]):.2f} - {np.max(rx_positions[:, 0]):.2f}")
            print(f"  Yåæ ‡èŒƒå›´: {np.min(rx_positions[:, 1]):.2f} - {np.max(rx_positions[:, 1]):.2f}")
            print(f"  Zåæ ‡èŒƒå›´: {np.min(rx_positions[:, 2]):.2f} - {np.max(rx_positions[:, 2]):.2f}")
    
    print("\n" + "-"*50)
    print("ğŸ“ˆ æ•°æ®å¯è§†åŒ–")
    print("-"*50)
    
    # åˆ›å»ºå¯è§†åŒ–
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    fig.suptitle('CFRæ•°æ®é›†åˆ†æå¯è§†åŒ–', fontsize=16)
    
    # 1. AP-STAå¯¹åˆ†å¸ƒ
    if 'TxID' in dataset.columns and 'RxID' in dataset.columns:
        pair_counts = dataset.groupby(['TxID', 'RxID']).size()
        ap_sta_matrix = pair_counts.unstack(fill_value=0)
        
        sns.heatmap(ap_sta_matrix, annot=True, fmt='d', cmap='Blues', ax=axes[0, 0])
        axes[0, 0].set_title('AP-STAå¯¹æ•°é‡åˆ†å¸ƒ')
        axes[0, 0].set_xlabel('STA ID (RxID)')
        axes[0, 0].set_ylabel('AP ID (TxID)')
    
    # 2. CFRå¹…åº¦åˆ†å¸ƒ
    if cfr_magnitudes:
        axes[0, 1].hist(cfr_magnitudes, bins=50, alpha=0.7, color='skyblue', edgecolor='black')
        axes[0, 1].set_title('CFRå¹…åº¦åˆ†å¸ƒ')
        axes[0, 1].set_xlabel('å¹…åº¦')
        axes[0, 1].set_ylabel('é¢‘æ¬¡')
        axes[0, 1].set_yscale('log')
    
    # 3. CFRç›¸ä½åˆ†å¸ƒ
    if cfr_phases:
        axes[0, 2].hist(cfr_phases, bins=50, alpha=0.7, color='lightgreen', edgecolor='black')
        axes[0, 2].set_title('CFRç›¸ä½åˆ†å¸ƒ')
        axes[0, 2].set_xlabel('ç›¸ä½ (å¼§åº¦)')
        axes[0, 2].set_ylabel('é¢‘æ¬¡')
    
    # 4. å®éƒ¨vsè™šéƒ¨æ•£ç‚¹å›¾
    if cfr_real_parts and cfr_imag_parts:
        # éšæœºé‡‡æ ·ç”¨äºå¯è§†åŒ–
        n_points = min(1000, len(cfr_real_parts))
        indices = np.random.choice(len(cfr_real_parts), n_points, replace=False)
        sample_real = [cfr_real_parts[i] for i in indices]
        sample_imag = [cfr_imag_parts[i] for i in indices]
        
        axes[1, 0].scatter(sample_real, sample_imag, alpha=0.5, s=1)
        axes[1, 0].set_title('CFRå¤æ•°å¹³é¢åˆ†å¸ƒ')
        axes[1, 0].set_xlabel('å®éƒ¨')
        axes[1, 0].set_ylabel('è™šéƒ¨')
        axes[1, 0].grid(True, alpha=0.3)
    
    # 5. STAä½ç½®åˆ†å¸ƒ
    if rx_positions is not None and len(rx_positions) > 0:
        axes[1, 1].scatter(rx_positions[:, 0], rx_positions[:, 1], alpha=0.6, s=10)
        axes[1, 1].set_title('STAä½ç½®åˆ†å¸ƒ (X-Yå¹³é¢)')
        axes[1, 1].set_xlabel('Xåæ ‡ (m)')
        axes[1, 1].set_ylabel('Yåæ ‡ (m)')
        axes[1, 1].grid(True, alpha=0.3)
    
    # 6. APä½ç½®åˆ†å¸ƒ
    if tx_positions is not None and len(tx_positions) > 0:
        unique_tx_pos = np.unique(tx_positions, axis=0)
        axes[1, 2].scatter(unique_tx_pos[:, 0], unique_tx_pos[:, 1], 
                          c='red', s=100, marker='^', label='AP')
        axes[1, 2].set_title('APä½ç½®åˆ†å¸ƒ (X-Yå¹³é¢)')
        axes[1, 2].set_xlabel('Xåæ ‡ (m)')
        axes[1, 2].set_ylabel('Yåæ ‡ (m)')
        axes[1, 2].grid(True, alpha=0.3)
        axes[1, 2].legend()
    
    plt.tight_layout()
    plt.savefig('/home/byang/BoYang/mNeWRF/dataset_analysis.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    print("âœ… å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜ä¸º 'dataset_analysis.png'")
    
    print("\n" + "="*80)
    print("ğŸ“‹ åˆ†æå®Œæˆ")
    print("="*80)

if __name__ == "__main__":
    dataset_path = '/home/byang/BoYang/NeWRF-main/simulator/datasets/conference_500STA_4APs.pkl'
    analyze_cfr_dataset(dataset_path)
