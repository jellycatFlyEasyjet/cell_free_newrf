#!/usr/bin/env python3
"""
æŸ¥çœ‹NASæœç´¢å¾—åˆ°çš„æœ€ä½³æ¨¡å‹æ¶æ„ - å®Œæ•´ç‰ˆæœ¬
å±•ç¤º get_architecture_info å‡½æ•°çš„å®é™…ç”¨é€”
"""

import pickle
import torch
import sys
import os

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from optuna_nas import OptimizedMLP

class FakeTrial:
    """ç”¨äºé‡å»ºæ¨¡å‹çš„è™šæ‹Ÿtrialç±»"""
    def __init__(self, params):
        self.params = params
    
    def suggest_int(self, name, low, high):
        return self.params.get(name, (low + high) // 2)
    
    def suggest_float(self, name, low, high):
        return self.params.get(name, (low + high) / 2)
    
    def suggest_loguniform(self, name, low, high):
        return self.params.get(name, (low * high) ** 0.5)
    
    def suggest_categorical(self, name, choices):
        return self.params.get(name, choices[0])

def load_and_view_best_model(params_file='final_best_params.pkl'):
    """åŠ è½½å¹¶æŸ¥çœ‹æœ€ä½³æ¨¡å‹æ¶æ„"""
    try:
        # åŠ è½½æœ€ä½³å‚æ•°
        with open(params_file, 'rb') as f:
            best_params = pickle.load(f)
        
        print("ğŸ“‹ æœ€ä½³æ¨¡å‹å‚æ•°:")
        print("=" * 60)
        
        # åˆ†ç±»æ˜¾ç¤ºå‚æ•°
        architecture_params = {}
        hyperparams = {}
        
        for key, value in best_params.items():
            if any(x in key for x in ['layer_', 'n_layers', 'use_batch_norm', 'init_method', 'skip_connections']):
                architecture_params[key] = value
            else:
                hyperparams[key] = value
        
        # æ˜¾ç¤ºæ¶æ„å‚æ•°
        print("ğŸ—ï¸ æ¶æ„å‚æ•°:")
        for key, value in sorted(architecture_params.items()):
            print(f"   {key}: {value}")
        
        print("\nâš™ï¸ è¶…å‚æ•°:")
        for key, value in sorted(hyperparams.items()):
            print(f"   {key}: {value}")
        
        # åˆ›å»ºæ¨¡å‹å¹¶æ˜¾ç¤ºè¯¦ç»†æ¶æ„
        print("\n" + "=" * 60)
        fake_trial = FakeTrial(best_params)
        model = OptimizedMLP(fake_trial)
        
        # æ˜¾ç¤ºè¯¦ç»†æ¶æ„ä¿¡æ¯
        model.print_architecture()
        
        # æ˜¾ç¤ºé¢å¤–ç»Ÿè®¡ä¿¡æ¯
        print(f"\nğŸ“Š æ¨¡å‹ç»Ÿè®¡:")
        arch_info = model.get_architecture_info()
        print(f"   æ€»å‚æ•°é‡: {arch_info['total_params']:,}")
        print(f"   å¯è®­ç»ƒå‚æ•°: {arch_info['trainable_params']:,}")
        
        # è®¡ç®—æ¯å±‚å‚æ•°é‡
        print(f"\nğŸ“ˆ æ¯å±‚å‚æ•°è¯¦æƒ…:")
        prev_size = 12  # è¾“å…¥ç»´åº¦
        total_layer_params = 0
        
        for i, config in enumerate(arch_info['layer_configs']):
            current_size = config['hidden_dim']
            layer_params = prev_size * current_size + current_size  # æƒé‡ + åç½®
            total_layer_params += layer_params
            print(f"   Layer {i}: {prev_size} â†’ {current_size} = {layer_params:,} å‚æ•°")
            prev_size = current_size
        
        # è¾“å‡ºå±‚å‚æ•°
        output_params = prev_size * 2 + 2  # è¾“å‡ºåˆ°å¤æ•°å€¼ (real + imag)
        total_layer_params += output_params
        print(f"   Output Layer: {prev_size} â†’ 2 = {output_params:,} å‚æ•°")
        print(f"   å±‚å‚æ•°æ€»è®¡: {total_layer_params:,}")
        
        return model, best_params
        
    except FileNotFoundError:
        print(f"âŒ æœªæ‰¾åˆ°å‚æ•°æ–‡ä»¶ '{params_file}'")
        print("è¯·å…ˆè¿è¡Œå®Œæ•´çš„NASæœç´¢: python optuna_nas.py")
        return None, None
    except Exception as e:
        print(f"âŒ åŠ è½½æ¨¡å‹æ—¶å‡ºé”™: {e}")
        return None, None

def view_study_results(study_file='architecture_study.db'):
    """æŸ¥çœ‹Optunaç ”ç©¶ç»“æœ"""
    try:
        import optuna
        
        print("\nğŸ“Š Optuna ç ”ç©¶ç»“æœ:")
        print("=" * 60)
        
        # åŠ è½½æ¶æ„æœç´¢ç ”ç©¶
        if os.path.exists('architecture_study.db'):
            study = optuna.load_study(
                study_name='architecture_optimization',
                storage='sqlite:///architecture_study.db'
            )
            
            print(f"ğŸ” æ¶æ„æœç´¢:")
            print(f"   æ€»è¯•éªŒæ•°: {len(study.trials)}")
            print(f"   æœ€ä½³è¯•éªŒ: #{study.best_trial.number}")
            print(f"   æœ€ä½³æŸå¤±: {study.best_value:.6f}")
            
            # æ˜¾ç¤ºæœ€é‡è¦çš„å‚æ•°
            print(f"\nğŸ† æœ€ä½³æ¶æ„å‚æ•°:")
            for key, value in study.best_params.items():
                if 'layer_' in key or key in ['n_layers', 'use_batch_norm', 'init_method']:
                    print(f"   {key}: {value}")
        
        # åŠ è½½è¶…å‚æ•°æœç´¢ç ”ç©¶
        if os.path.exists('hyperparams_study.db'):
            hp_study = optuna.load_study(
                study_name='hyperparams_optimization', 
                storage='sqlite:///hyperparams_study.db'
            )
            
            print(f"\nâš™ï¸ è¶…å‚æ•°æœç´¢:")
            print(f"   æ€»è¯•éªŒæ•°: {len(hp_study.trials)}")
            print(f"   æœ€ä½³è¯•éªŒ: #{hp_study.best_trial.number}")
            print(f"   æœ€ä½³æŸå¤±: {hp_study.best_value:.6f}")
            
    except ImportError:
        print("âŒ éœ€è¦å®‰è£…optuna: pip install optuna")
    except Exception as e:
        print(f"âŒ æŸ¥çœ‹ç ”ç©¶ç»“æœæ—¶å‡ºé”™: {e}")

if __name__ == "__main__":
    print("ğŸ” æŸ¥çœ‹æœ€ä½³ç¥ç»ç½‘ç»œæ¶æ„")
    print("=" * 60)
    
    # æŸ¥çœ‹æœ€ä½³æ¨¡å‹
    model, params = load_and_view_best_model()
    
    if model is not None:
        print(f"\nâœ… æˆåŠŸåŠ è½½æœ€ä½³æ¨¡å‹!")
        
        # å¯é€‰ï¼šæŸ¥çœ‹Optunaç ”ç©¶ç»“æœ
        print("\n" + "="*60)
        view_study_results()
    
    print("\nğŸ¯ æ¶æ„æŸ¥çœ‹å®Œæˆ!")
