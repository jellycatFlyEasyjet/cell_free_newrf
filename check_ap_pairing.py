#!/usr/bin/env python3
"""
æ£€æŸ¥APé—´CFRæ•°æ®çš„é…å¯¹å…³ç³»å’Œç»´åº¦é—®é¢˜
"""

import pandas as pd
import numpy as np
from collections import defaultdict, Counter

def check_ap_pairing(dataset_path):
    """æ£€æŸ¥APé—´çš„é…å¯¹å…³ç³»"""
    
    print("="*80)
    print("ğŸ” APé…å¯¹å…³ç³»åˆ†æ")
    print("="*80)
    
    dataset = pd.read_pickle(dataset_path)
    dataset = dataset.dropna()
    
    print(f"æ•°æ®é›†å¤§å°: {len(dataset)} æ¡è®°å½•")
    print(f"æ€»APæ•°: {len(dataset['TxID'].unique())}")
    print(f"æ€»STAæ•°: {len(dataset['RxID'].unique())}")
    
    # åˆ†æAP-STAé…å¯¹
    print(f"\nğŸ“Š AP-STAé…å¯¹åˆ†æ:")
    
    # æŒ‰STAåˆ†ç»„ï¼Œçœ‹æ¯ä¸ªSTAä¸å¤šå°‘ä¸ªAPæœ‰è¿æ¥
    sta_ap_counts = defaultdict(list)
    for _, row in dataset.iterrows():
        sta_id = int(row['RxID'])
        ap_id = int(row['TxID'])
        sta_ap_counts[sta_id].append(ap_id)
    
    # ç»Ÿè®¡æ¯ä¸ªSTAè¿æ¥çš„APæ•°é‡
    ap_count_distribution = Counter([len(aps) for aps in sta_ap_counts.values()])
    print(f"  STAè¿æ¥APæ•°é‡åˆ†å¸ƒ: {dict(ap_count_distribution)}")
    
    # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰STAéƒ½è¿æ¥åˆ°ç›¸åŒæ•°é‡çš„AP
    ap_counts_per_sta = [len(aps) for aps in sta_ap_counts.values()]
    if len(set(ap_counts_per_sta)) == 1:
        print(f"  âœ… æ‰€æœ‰STAéƒ½è¿æ¥åˆ° {ap_counts_per_sta[0]} ä¸ªAP")
    else:
        print(f"  âš ï¸ STAè¿æ¥çš„APæ•°é‡ä¸ä¸€è‡´: {set(ap_counts_per_sta)}")
    
    # åˆ†æç‰¹å®šåœºæ™¯ï¼šbase_AP=[1], target_AP=[2]
    print(f"\nğŸ¯ ç‰¹å®šé…ç½®åˆ†æ (base_AP=[1], target_AP=[2]):")
    
    base_ap = 1
    target_ap = 2
    
    # æ£€æŸ¥æœ‰å¤šå°‘STAåŒæ—¶è¿æ¥åˆ°AP1å’ŒAP2
    sta_with_ap1 = set(dataset[dataset['TxID'] == base_ap]['RxID'])
    sta_with_ap2 = set(dataset[dataset['TxID'] == target_ap]['RxID'])
    
    common_stas = sta_with_ap1 & sta_with_ap2
    
    print(f"  è¿æ¥åˆ°AP{base_ap}çš„STAæ•°é‡: {len(sta_with_ap1)}")
    print(f"  è¿æ¥åˆ°AP{target_ap}çš„STAæ•°é‡: {len(sta_with_ap2)}")
    print(f"  åŒæ—¶è¿æ¥åˆ°AP{base_ap}å’ŒAP{target_ap}çš„STAæ•°é‡: {len(common_stas)}")
    
    if len(common_stas) != len(sta_with_ap1) or len(common_stas) != len(sta_with_ap2):
        print(f"  âš ï¸ è­¦å‘Šï¼šä¸æ˜¯æ‰€æœ‰STAéƒ½åŒæ—¶è¿æ¥åˆ°è¿™ä¸¤ä¸ªAP")
        only_ap1 = sta_with_ap1 - sta_with_ap2
        only_ap2 = sta_with_ap2 - sta_with_ap1
        if only_ap1:
            print(f"    åªè¿æ¥åˆ°AP{base_ap}çš„STA: {sorted(list(only_ap1))[:10]}...")
        if only_ap2:
            print(f"    åªè¿æ¥åˆ°AP{target_ap}çš„STA: {sorted(list(only_ap2))[:10]}...")
    else:
        print(f"  âœ… æ‰€æœ‰STAéƒ½åŒæ—¶è¿æ¥åˆ°AP{base_ap}å’ŒAP{target_ap}")
    
    # æ¨¡æ‹Ÿæ•°æ®åŠ è½½è¿‡ç¨‹
    print(f"\nğŸ§ª æ¨¡æ‹Ÿæ•°æ®åŠ è½½è¿‡ç¨‹:")
    
    def simulate_get_cfr_batch(ap_ids, sta_ids):
        """æ¨¡æ‹Ÿget_cfr_batchå‡½æ•°"""
        cfr_list = []
        found_pairs = []
        
        for sta_id in sta_ids:
            for ap_id in ap_ids:
                pair = dataset[(dataset['TxID'] == ap_id) & (dataset['RxID'] == sta_id)]
                if not pair.empty:
                    cfr = pair['CSI'].iloc[0]
                    if isinstance(cfr, np.ndarray) and len(cfr) > 0:
                        cfr_list.append(cfr.flatten())
                        found_pairs.append((ap_id, sta_id))
                else:
                    print(f"    âš ï¸ æœªæ‰¾åˆ° AP{ap_id}-STA{sta_id} çš„CFRæ•°æ®")
        
        return np.array(cfr_list), found_pairs
    
    # æ¨¡æ‹Ÿbatch_size=5çš„æƒ…å†µ
    test_batch_size = 5
    available_stas = sorted(list(common_stas))[:test_batch_size]
    
    print(f"  æµ‹è¯•batch: STAs {available_stas}")
    
    # è·å–base_APçš„CFR
    base_cfr, base_pairs = simulate_get_cfr_batch([base_ap], available_stas)
    print(f"  Base AP{base_ap} CFRå½¢çŠ¶: {base_cfr.shape}")
    print(f"  Base APé…å¯¹: {base_pairs}")
    
    # è·å–target_APçš„CFR
    target_cfr, target_pairs = simulate_get_cfr_batch([target_ap], available_stas)
    print(f"  Target AP{target_ap} CFRå½¢çŠ¶: {target_cfr.shape}")
    print(f"  Target APé…å¯¹: {target_pairs}")
    
    # æ£€æŸ¥ç»´åº¦åŒ¹é…
    if base_cfr.shape[0] == target_cfr.shape[0] == len(available_stas):
        print(f"  âœ… ç»´åº¦åŒ¹é…ï¼š{base_cfr.shape[0]} == {target_cfr.shape[0]} == {len(available_stas)}")
    else:
        print(f"  âŒ ç»´åº¦ä¸åŒ¹é…ï¼šbase_cfr={base_cfr.shape[0]}, target_cfr={target_cfr.shape[0]}, batch_size={len(available_stas)}")
    
    # åˆ†æä½ç½®æ•°æ®
    print(f"\nğŸ“ ä½ç½®æ•°æ®åˆ†æ:")
    
    def simulate_get_loc_batch(dev_type, sta_ids):
        """æ¨¡æ‹Ÿget_loc_batchå‡½æ•°"""
        if dev_type == "STA":
            loc_list = []
            for sta_id in sta_ids:
                sta_data = dataset[dataset['RxID'] == sta_id]
                if not sta_data.empty:
                    loc = sta_data['RxPos'].iloc[0]
                    loc_list.append(loc)
                else:
                    print(f"    âš ï¸ æœªæ‰¾åˆ°STA{sta_id}çš„ä½ç½®æ•°æ®")
            return np.array(loc_list)
        
        elif dev_type == "AP":
            # è¿™é‡Œæ¨¡æ‹ŸåŸå§‹ä»£ç çš„é€»è¾‘
            if sta_ids:
                sta_data = dataset[dataset['RxID'] == sta_ids[0]]
                if not sta_data.empty:
                    # è·å–ä¸ç¬¬ä¸€ä¸ªSTAç›¸å…³çš„æ‰€æœ‰APä½ç½®
                    ap_positions = []
                    for _, row in sta_data.iterrows():
                        ap_pos = row['TxPos']
                        ap_positions.append(ap_pos)
                    return np.array(ap_positions)
            return np.array([])
    
    sta_locs = simulate_get_loc_batch("STA", available_stas)
    ap_locs = simulate_get_loc_batch("AP", available_stas)
    
    print(f"  STAä½ç½®æ•°æ®å½¢çŠ¶: {sta_locs.shape}")
    print(f"  APä½ç½®æ•°æ®å½¢çŠ¶: {ap_locs.shape}")
    
    # æ£€æŸ¥æœ€ç»ˆç»´åº¦åŒ¹é…
    print(f"\nğŸ”§ æœ€ç»ˆç»´åº¦æ£€æŸ¥:")
    print(f"  STAä½ç½®: {sta_locs.shape}")
    print(f"  Base CFR: {base_cfr.shape}")
    print(f"  Target CFR: {target_cfr.shape}")
    
    if sta_locs.shape[0] == base_cfr.shape[0]:
        print(f"  âœ… STAä½ç½®ä¸Base CFRç»´åº¦åŒ¹é…")
    else:
        print(f"  âŒ STAä½ç½®ä¸Base CFRç»´åº¦ä¸åŒ¹é…: {sta_locs.shape[0]} vs {base_cfr.shape[0]}")
        print(f"      è¿™å°±æ˜¯å¯¼è‡´ RuntimeError çš„åŸå› ï¼")
    
    # ç»™å‡ºè§£å†³å»ºè®®
    print(f"\nğŸ’¡ è§£å†³å»ºè®®:")
    print(f"  1. ç¡®ä¿æ‰¹æ¬¡ä¸­çš„æ‰€æœ‰STAéƒ½æœ‰å¯¹åº”çš„AP CFRæ•°æ®")
    print(f"  2. æ£€æŸ¥get_loc_batchå‡½æ•°æ˜¯å¦æ­£ç¡®è¿”å›å¯¹åº”æ•°é‡çš„ä½ç½®")
    print(f"  3. è€ƒè™‘åœ¨æ•°æ®åŠ è½½æ—¶è¿›è¡Œç»´åº¦éªŒè¯")
    print(f"  4. è¿‡æ»¤æ‰ä¸å®Œæ•´çš„STA-APé…å¯¹")

if __name__ == "__main__":
    dataset_path = '/home/byang/BoYang/NeWRF-main/simulator/datasets/conference_500STA_4APs.pkl'
    check_ap_pairing(dataset_path)
