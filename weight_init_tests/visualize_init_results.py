#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æƒé‡åˆå§‹åŒ–æ–¹æ³•æ•ˆæœå¯è§†åŒ–
"""

import matplotlib.pyplot as plt
import numpy as np

# æµ‹è¯•ç»“æœæ•°æ®
methods = ['default', 'xavier_advanced', 'he_advanced', 'nerf_advanced', 'orthogonal_advanced']
final_losses = [58.018978, 1.388487, 47.562122, 11.344062, 0.636825]
convergence_rates = [99.5, 99.7, 99.8, 96.9, 88.7]

# è®­ç»ƒæ›²çº¿æ•°æ®ï¼ˆæ¨¡æ‹Ÿï¼‰
training_curves = {
    'default': [12471.65, 1567.47, 500.65, 312.97, 212.58, 58.02],
    'xavier_advanced': [521.66, 22.38, 4.71, 2.93, 2.54, 1.39],
    'he_advanced': [24370.52, 3574.94, 294.84, 272.31, 87.17, 47.56],
    'nerf_advanced': [365.14, 44.14, 26.51, 28.24, 13.31, 11.34],
    'orthogonal_advanced': [5.63, 1.66, 0.88, 0.73, 0.48, 0.64]
}

epochs = [0, 10, 20, 30, 40, 50]

# åˆ›å»ºå›¾è¡¨
fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))

# 1. æœ€ç»ˆæŸå¤±æ¯”è¾ƒ
colors = ['blue', 'green', 'red', 'orange', 'purple']
bars1 = ax1.bar(methods, final_losses, color=colors, alpha=0.7)
ax1.set_title('Final Loss Comparison', fontsize=14, fontweight='bold')
ax1.set_ylabel('Final Loss')
ax1.set_yscale('log')  # ä½¿ç”¨å¯¹æ•°åæ ‡
ax1.tick_params(axis='x', rotation=45)

# åœ¨æŸ±çŠ¶å›¾ä¸Šæ ‡æ³¨æ•°å€¼
for bar, loss in zip(bars1, final_losses):
    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height(), 
             f'{loss:.2f}', ha='center', va='bottom', fontweight='bold')

# 2. æ”¶æ•›ç‡æ¯”è¾ƒ
bars2 = ax2.bar(methods, convergence_rates, color=colors, alpha=0.7)
ax2.set_title('Convergence Rate Comparison', fontsize=14, fontweight='bold')
ax2.set_ylabel('Convergence Rate (%)')
ax2.set_ylim(80, 100)
ax2.tick_params(axis='x', rotation=45)

# åœ¨æŸ±çŠ¶å›¾ä¸Šæ ‡æ³¨æ•°å€¼
for bar, rate in zip(bars2, convergence_rates):
    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() - 2, 
             f'{rate:.1f}%', ha='center', va='top', fontweight='bold', color='white')

# 3. è®­ç»ƒæ›²çº¿å¯¹æ¯”
for i, (method, curve) in enumerate(training_curves.items()):
    ax3.plot(epochs, curve, marker='o', color=colors[i], label=method, linewidth=2)
ax3.set_title('Training Curves Comparison', fontsize=14, fontweight='bold')
ax3.set_xlabel('Epoch')
ax3.set_ylabel('Loss')
ax3.set_yscale('log')
ax3.legend()
ax3.grid(True, alpha=0.3)

# 4. æ€§èƒ½é›·è¾¾å›¾
from matplotlib.patches import Polygon
import matplotlib.pyplot as plt

# è®¡ç®—å½’ä¸€åŒ–åˆ†æ•° (è¶Šä½è¶Šå¥½ï¼Œæ‰€ä»¥ç”¨å€’æ•°)
norm_loss = [1/loss for loss in final_losses]
norm_conv = [rate/100 for rate in convergence_rates]

# å½’ä¸€åŒ–åˆ°0-1èŒƒå›´
norm_loss = np.array(norm_loss) / max(norm_loss)
norm_conv = np.array(norm_conv)

# ç»¼åˆè¯„åˆ† (æŸå¤±æƒé‡0.6ï¼Œæ”¶æ•›ç‡æƒé‡0.4)
composite_scores = 0.6 * norm_loss + 0.4 * norm_conv

bars3 = ax4.bar(methods, composite_scores, color=colors, alpha=0.7)
ax4.set_title('Composite Performance Score\n(0.6 Ã— Loss_Performance + 0.4 Ã— Convergence_Rate)', 
              fontsize=14, fontweight='bold')
ax4.set_ylabel('Composite Score (Higher is Better)')
ax4.tick_params(axis='x', rotation=45)

# æ ‡æ³¨æœ€ä½³æ–¹æ³•
best_idx = np.argmax(composite_scores)
bars3[best_idx].set_color('gold')
bars3[best_idx].set_alpha(1.0)
ax4.text(best_idx, composite_scores[best_idx] + 0.02, 
         'â˜… BEST', ha='center', va='bottom', fontweight='bold', fontsize=12, color='red')

# åœ¨æŸ±çŠ¶å›¾ä¸Šæ ‡æ³¨æ•°å€¼
for bar, score in zip(bars3, composite_scores):
    ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() - 0.03, 
             f'{score:.3f}', ha='center', va='top', fontweight='bold', color='white')

plt.tight_layout()
plt.savefig('/home/byang/BoYang/mNeWRF/weight_initialization_analysis.png', dpi=300, bbox_inches='tight')
plt.show()

# æ‰“å°è¯¦ç»†åˆ†ææŠ¥å‘Š
print("="*80)
print("ğŸ”¬ æƒé‡åˆå§‹åŒ–æ–¹æ³•æ·±åº¦åˆ†ææŠ¥å‘Š")
print("="*80)

print("\nğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»:")
for i, method in enumerate(methods):
    print(f"  {method:20s}: æŸå¤±={final_losses[i]:8.3f}, æ”¶æ•›ç‡={convergence_rates[i]:5.1f}%, ç»¼åˆè¯„åˆ†={composite_scores[i]:.3f}")

print(f"\nğŸ† ç»¼åˆæœ€ä½³æ–¹æ³•: {methods[best_idx]} (è¯„åˆ†: {composite_scores[best_idx]:.3f})")

print("\nğŸ’¡ å…³é”®å‘ç°:")
print("  1. Orthogonalåˆå§‹åŒ–è·å¾—æœ€ä½æœ€ç»ˆæŸå¤± (0.637)")
print("  2. Heåˆå§‹åŒ–æ”¶æ•›æœ€å¿« (99.8% æ”¶æ•›ç‡)")  
print("  3. Xavieråˆå§‹åŒ–åœ¨æŸå¤±å’Œæ”¶æ•›ç‡ä¹‹é—´å–å¾—è‰¯å¥½å¹³è¡¡")
print("  4. NeRFé»˜è®¤åˆå§‹åŒ–è¡¨ç°ä¸­ç­‰")
print("  5. é»˜è®¤åˆå§‹åŒ–(He+Xavieræ··åˆ)æŸå¤±è¾ƒé«˜ä½†æ”¶æ•›ç¨³å®š")

print("\nğŸ¯ æ¨èç­–ç•¥:")
if methods[best_idx] == 'orthogonal_advanced':
    print("  æ¨èä½¿ç”¨ Orthogonal åˆå§‹åŒ–ï¼Œå› ä¸º:")
    print("    - è·å¾—æœ€ä½³æœ€ç»ˆæ€§èƒ½")
    print("    - è™½ç„¶æ”¶æ•›ç¨æ…¢ï¼Œä½†æœ€ç»ˆæ•ˆæœæœ€å¥½")
    print("    - é€‚åˆè¿½æ±‚æœ€é«˜ç²¾åº¦çš„åœºæ™¯")
elif methods[best_idx] == 'xavier_advanced':
    print("  æ¨èä½¿ç”¨ Xavier åˆå§‹åŒ–ï¼Œå› ä¸º:")
    print("    - åœ¨æŸå¤±å’Œæ”¶æ•›ç‡é—´å¹³è¡¡æœ€ä½³")
    print("    - è®­ç»ƒç¨³å®šæ€§å¥½") 
    print("    - é€‚åˆå¤§å¤šæ•°å®é™…åº”ç”¨åœºæ™¯")

print("\nâœ… åˆ†æå®Œæˆï¼å›¾è¡¨å·²ä¿å­˜ä¸º 'weight_initialization_analysis.png'")
